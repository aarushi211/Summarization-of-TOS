{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17cfd4fb-bba5-4db3-97aa-2a1cb74694b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbba5b2-3504-447b-b65a-4fce44c05b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>reference_summary</th>\n",
       "      <th>title</th>\n",
       "      <th>uid</th>\n",
       "      <th>case_code</th>\n",
       "      <th>case_text</th>\n",
       "      <th>note</th>\n",
       "      <th>title_code</th>\n",
       "      <th>title_text</th>\n",
       "      <th>urls</th>\n",
       "      <th>tldr_code</th>\n",
       "      <th>tldr_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pokemon GO Terms of Service</td>\n",
       "      <td>5786730a6cca83a54c0035b7</td>\n",
       "      <td>welcome to the pokémon go video game services ...</td>\n",
       "      <td>hi.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>legalsum01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pokemon GO Terms of Service</td>\n",
       "      <td>57866df76cca83a54c0035a1</td>\n",
       "      <td>by using our services you are agreeing to thes...</td>\n",
       "      <td>by playing this game you agree to these terms....</td>\n",
       "      <td>Agreement To Terms</td>\n",
       "      <td>legalsum02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pokemon GO Terms of Service</td>\n",
       "      <td>5786730a6cca83a54c0035b6</td>\n",
       "      <td>if you want to use certain features of the ser...</td>\n",
       "      <td>you have to use google pokemon trainer club or...</td>\n",
       "      <td>Eligibility and Account Registration</td>\n",
       "      <td>legalsum03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pokemon GO Terms of Service</td>\n",
       "      <td>57866df76cca83a54c0035a0</td>\n",
       "      <td>during game play please be aware of your surro...</td>\n",
       "      <td>don t die or hurt others and if you do it s no...</td>\n",
       "      <td>Safe Play</td>\n",
       "      <td>legalsum04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pokemon GO Terms of Service</td>\n",
       "      <td>57866df76cca83a54c00359f</td>\n",
       "      <td>subject to your compliance with these terms ni...</td>\n",
       "      <td>don t copy modify resell distribute or reverse...</td>\n",
       "      <td>Rights in App</td>\n",
       "      <td>legalsum05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           doc                        id  \\\n",
       "0  Pokemon GO Terms of Service  5786730a6cca83a54c0035b7   \n",
       "1  Pokemon GO Terms of Service  57866df76cca83a54c0035a1   \n",
       "2  Pokemon GO Terms of Service  5786730a6cca83a54c0035b6   \n",
       "3  Pokemon GO Terms of Service  57866df76cca83a54c0035a0   \n",
       "4  Pokemon GO Terms of Service  57866df76cca83a54c00359f   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  welcome to the pokémon go video game services ...   \n",
       "1  by using our services you are agreeing to thes...   \n",
       "2  if you want to use certain features of the ser...   \n",
       "3  during game play please be aware of your surro...   \n",
       "4  subject to your compliance with these terms ni...   \n",
       "\n",
       "                                   reference_summary  \\\n",
       "0                                                hi.   \n",
       "1  by playing this game you agree to these terms....   \n",
       "2  you have to use google pokemon trainer club or...   \n",
       "3  don t die or hurt others and if you do it s no...   \n",
       "4  don t copy modify resell distribute or reverse...   \n",
       "\n",
       "                                  title         uid case_code case_text note  \\\n",
       "0                                   NaN  legalsum01       NaN       NaN  NaN   \n",
       "1                    Agreement To Terms  legalsum02       NaN       NaN  NaN   \n",
       "2  Eligibility and Account Registration  legalsum03       NaN       NaN  NaN   \n",
       "3                             Safe Play  legalsum04       NaN       NaN  NaN   \n",
       "4                         Rights in App  legalsum05       NaN       NaN  NaN   \n",
       "\n",
       "  title_code title_text urls tldr_code tldr_text  \n",
       "0        NaN        NaN  NaN       NaN       NaN  \n",
       "1        NaN        NaN  NaN       NaN       NaN  \n",
       "2        NaN        NaN  NaN       NaN       NaN  \n",
       "3        NaN        NaN  NaN       NaN       NaN  \n",
       "4        NaN        NaN  NaN       NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Dataset/all_v1_transpose.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e88146d-a71e-4f6a-bf70-3a1c8be6befe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['doc'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7790665-6460-4d94-a0f1-7469266cf6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab2d3a-907c-44d6-b922-8f60f66e7622",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba26e8e5-4ed9-4a43-bfc8-c2e0952b6e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarus\\rag-uv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3975d1bd-7cfb-4f44-82a6-0cb02de77939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pdf\n",
    "def load_pdf(pdf_path):\n",
    "    pdf_path = Path(pdf_path)\n",
    "    print(f'Loading {pdf_path.name}...')\n",
    "\n",
    "    # loading pdf\n",
    "    loader = PyPDFLoader(str(pdf_path))\n",
    "    pdf = loader.load()\n",
    "    print(f'Found {pdf_path.name} with {len(pdf)} pages.')\n",
    "\n",
    "    for page in pdf:\n",
    "        page.metadata['source_file'] = pdf_path.name\n",
    "        page.metadata['file_type'] = 'pdf'\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc83ffc-3ce3-4063-b3fa-db748fe95983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d21009-f73a-4729-a403-411a1b39c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking pdf\n",
    "def split_doc(doc, chunk_size = 1000, chunk_overlap = 200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap, \n",
    "        length_function = len,\n",
    "        separators=['\\n\\n', '\\n', '', ' ']\n",
    "    )\n",
    "    split_doc = text_splitter.split_documents(doc)\n",
    "    print(f\"Split {len(doc)} documents into {len(split_doc)} chunks\")    \n",
    "    return split_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae07de1-ed23-411a-a398-11ac8e410fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d574ad7d-c1e9-44a1-a8c1-4bc3f5f73ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager:\n",
    "    '''Handles doc embedding generation using SentenceTransformer'''\n",
    "    def __init__(self, model_name = 'all-MiniLM-L6-v2'):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        '''load SentenceTransformer model'''\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts):\n",
    "        '''Generate Embeddings for a list of texts'''\n",
    "        if not self.model:\n",
    "            raise ValueError('Model not loaded')\n",
    "        # print(f\"Generating embeddings for {(texts)} ...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar = True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e4860f-8095-4ccd-ac2a-5bd89581ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    '''Manage doc embeddings in ChromaDB vector store'''\n",
    "    def __init__(self, collection_name = 'pdf', persist_directory = '../data/vector_store'):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        'Initialize chromadb client and collection'''\n",
    "        try:\n",
    "            # Creating persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok = True)\n",
    "            self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "\n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata={\"hnsw:space\": \"cosine\", \"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents, embeddings):\n",
    "        '''Add documents and their embeddings to the vector store'''\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        doc_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique IDs\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # Metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Doc content\n",
    "            doc_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids = ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=doc_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e28089-567e-4d6f-86b0-2dc4d86acbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetrieval:\n",
    "    def __init__(self, vector_store, embedding_manager):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query, top_k = 5, score_threshold = 0.0):\n",
    "        '''Retrieve relevant docs for the query'''\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "\n",
    "        # generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings(query)\n",
    "\n",
    "        # search in vectorstore\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings = [query_embedding.tolist()],\n",
    "                n_results = top_k\n",
    "            )\n",
    "            retrieved_doc = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids,documents, metadatas, distances)):\n",
    "                    # convert distance to similarity score. Chromadb uses cosine\n",
    "                    similarity_score = 1 - distance\n",
    "\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_doc.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                print(f\"Retrieved {len(retrieved_doc)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_doc\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04c8686b-67b2-494f-a75d-7c05209fcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, LEDForConditionalGeneration, LEDTokenizer\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f9cc3dd-da60-4b19-95bf-c51b0830c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.chunk_summarizer = None\n",
    "        self.final_summarizer = None\n",
    "        self._load_pipelines()\n",
    "\n",
    "    def _load_pipelines(self):\n",
    "        try:\n",
    "            print(f\"Loading your fine-tuned model '{self.model.name_or_path}' into pipeline...\")\n",
    "\n",
    "            self.chunk_summarizer = pipeline(\n",
    "                'summarization',\n",
    "                model = self.model,\n",
    "                tokenizer= self.tokenizer,\n",
    "                device = -1\n",
    "            )\n",
    "            print(\"Successfully loaded the model.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading local model into pipeline: {e}\")\n",
    "\n",
    "        print(\"Loading final combination summarizer (bart-large-cnn)...\")\n",
    "        self.final_summarizer = pipeline(\n",
    "            \"summarization\", \n",
    "            model=\"facebook/bart-large-cnn\", \n",
    "            device=-1\n",
    "        )\n",
    "        print(\"All models loaded.\")\n",
    "\n",
    "    def summarize(self, retrieved_docs, max_chunk_len = 150, min_chunk_len=30, final_summary_len=512):\n",
    "        chunk_summaries = []\n",
    "        print(f\"\\nSummarizing {len(retrieved_docs)} retrieved chunks...\")\n",
    "        for doc in retrieved_docs:\n",
    "            content = doc['content']\n",
    "            \n",
    "            # Use YOUR model to summarize the chunk\n",
    "            chunk_summary = self.chunk_summarizer(\n",
    "                content, \n",
    "                max_length=max_chunk_len, \n",
    "                min_length=min_chunk_len\n",
    "            )\n",
    "            chunk_summaries.append(chunk_summary[0]['summary_text'])\n",
    "            \n",
    "        print(\"Chunk summarization complete.\")\n",
    "\n",
    "        # --- Step 2: Combine the chunk summaries into one text ---\n",
    "        combined_text = \"\\n\\n\".join(chunk_summaries)\n",
    "        \n",
    "        print(\"\\nCombining summaries into final summary...\")\n",
    "        # --- Step 3: Summarize the combined text ---\n",
    "        final_summary = self.final_summarizer(\n",
    "            combined_text, \n",
    "            max_length=final_summary_len, \n",
    "            min_length=100\n",
    "        )\n",
    "        \n",
    "        return final_summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd574e9c-99e0-4b7b-bfef-88b45e59c40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Terms of Service Youtube.pdf...\n",
      "Found Terms of Service Youtube.pdf with 16 pages.\n",
      "Split 16 documents into 34 chunks\n",
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n",
      "Vector store initialized. Collection: pdf\n",
      "Existing documents in collection: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (34, 384)\n",
      "Adding 34 documents to vector store...\n",
      "Successfully added 34 documents to vector store\n",
      "Total documents in collection: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Tokenizer loaded.\n",
      "Loading your fine-tuned model 'aarushi-211/TOS-Longformer' into pipeline...\n",
      "Successfully loaded the model.\n",
      "Loading final combination summarizer (bart-large-cnn)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models loaded.\n",
      "\n",
      "--- Retrieving chunks for query: 'What are the most important user responsibilities, liabilities, and service termination clauses?' ---\n",
      "Retrieving documents for query: 'What are the most important user responsibilities, liabilities, and service termination clauses?'\n",
      "Top K: 5, Score threshold: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 52.24it/s]\n",
      "Input ids are automatically padded from 361 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (384,)\n",
      "Retrieved 5 documents (after filtering)\n",
      "\n",
      "--- Generating final summary ---\n",
      "\n",
      "Summarizing 5 retrieved chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Input ids are automatically padded from 254 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Your max_length is set to 512, but your input_length is only 217. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk summarization complete.\n",
      "\n",
      "Combining summaries into final summary...\n",
      "\n",
      "\n",
      "========== FINAL SUMMARY ==========\n",
      "users are not liable for anything bad that happens when using the service. we don t make warranties about anything bad. that happens. we may be involved in operating the service, so please contact us if you want to discuss how you would like to use it. We are happy to help you with any questions you may have about the service or how it works. Please contact us with questions about how to use the service and we will try to answer them as soon as possible. Back to Mail Online home.\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "pdf = load_pdf('../Dataset/Terms of Service Youtube.pdf')\n",
    "chunks=split_doc(pdf)\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "\n",
    "vectorstore = VectorStore()\n",
    "\n",
    "# convert text to embedding\n",
    "text = [doc.page_content for doc in chunks]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(text)\n",
    "\n",
    "# store in vectordb\n",
    "vectorstore.add_documents(chunks, embeddings)\n",
    "\n",
    "rag_retriever=RAGRetrieval(vectorstore,embedding_manager)\n",
    "\n",
    "model_name = \"aarushi-211/TOS-Longformer\" \n",
    "model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
    "print(\"Model and Tokenizer loaded.\")\n",
    "\n",
    "generator = Generator(model=model, tokenizer=tokenizer)\n",
    "\n",
    "query = \"What are the most important user responsibilities, liabilities, and service termination clauses?\"\n",
    "\n",
    "\n",
    "print(f\"\\n--- Retrieving chunks for query: '{query}' ---\")\n",
    "retrieved_documents = rag_retriever.retrieve(query, top_k=5)\n",
    "\n",
    "if retrieved_documents:\n",
    "    print(\"\\n--- Generating final summary ---\")\n",
    "    final_summary = generator.summarize(retrieved_documents)\n",
    "    \n",
    "    print(\"\\n\\n========== FINAL SUMMARY ==========\")\n",
    "    print(final_summary)\n",
    "    print(\"===================================\")\n",
    "else:\n",
    "    print(\"No relevant documents were retrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26490b2-a20a-4485-9d33-054aecfd659d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-uv",
   "language": "python",
   "name": "rag-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
