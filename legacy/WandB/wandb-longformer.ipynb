{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T09:46:07.231474Z",
     "iopub.status.busy": "2023-10-26T09:46:07.230673Z",
     "iopub.status.idle": "2023-10-26T09:47:08.838068Z",
     "shell.execute_reply": "2023-10-26T09:47:08.836639Z",
     "shell.execute_reply.started": "2023-10-26T09:46:07.231437Z"
    },
    "id": "C-OBrGewb_Wu",
    "outputId": "fb6dde92-42df-4237-f955-1f551db4c196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.30 in /opt/conda/lib/python3.10/site-packages (4.30.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (2023.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.30) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30) (2023.7.22)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.16.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.6.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n",
      "Requirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.30\n",
    "!pip install accelerate -U\n",
    "!pip install sentencepiece\n",
    "!pip install rouge\n",
    "!pip install wandb onnx -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T09:47:08.840599Z",
     "iopub.status.busy": "2023-10-26T09:47:08.840282Z",
     "iopub.status.idle": "2023-10-26T09:47:09.843462Z",
     "shell.execute_reply": "2023-10-26T09:47:09.842359Z",
     "shell.execute_reply.started": "2023-10-26T09:47:08.840571Z"
    },
    "id": "8-7bYF_qvTDT",
    "outputId": "67907995-ed97-4365-8f6d-31f8f706ce20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'TOS-Summarization' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Arjavjain100/TOS-Summarization.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:47:09.845275Z",
     "iopub.status.busy": "2023-10-26T09:47:09.844974Z",
     "iopub.status.idle": "2023-10-26T09:47:17.344279Z",
     "shell.execute_reply": "2023-10-26T09:47:17.343270Z",
     "shell.execute_reply.started": "2023-10-26T09:47:09.845246Z"
    },
    "id": "7KBtpTeJbcsA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import LEDForConditionalGeneration, LEDTokenizer, Trainer, TrainingArguments,pipeline,PretrainedConfig\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge import Rouge\n",
    "import pandas as pd\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import accelerate\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"]=\"major-one\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"checkpoint\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"all\"\n",
    "\n",
    "\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset location\n",
    "filename = \"./TOS-Summarization/Dataset/all_v1_transpose.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:48:20.112576Z",
     "iopub.status.busy": "2023-10-26T09:48:20.112279Z",
     "iopub.status.idle": "2023-10-26T09:48:32.690811Z",
     "shell.execute_reply": "2023-10-26T09:48:32.689447Z",
     "shell.execute_reply.started": "2023-10-26T09:48:20.112549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.12)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.30.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T09:48:32.692788Z",
     "iopub.status.busy": "2023-10-26T09:48:32.692453Z",
     "iopub.status.idle": "2023-10-26T09:48:33.742706Z",
     "shell.execute_reply": "2023-10-26T09:48:33.741679Z",
     "shell.execute_reply.started": "2023-10-26T09:48:32.692756Z"
    },
    "id": "NquUD6lhfBHO",
    "outputId": "47d4f550-2eb9-4b7a-b273-73ad2c3800d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
      "/bin/bash: -c: line 1: `wandb login()'\n"
     ]
    }
   ],
   "source": [
    "!wandb login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:00.417886Z",
     "iopub.status.busy": "2023-10-26T09:49:00.417478Z",
     "iopub.status.idle": "2023-10-26T09:49:00.444373Z",
     "shell.execute_reply": "2023-10-26T09:49:00.443295Z",
     "shell.execute_reply.started": "2023-10-26T09:49:00.417853Z"
    },
    "id": "ERL_fIRDcBOB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df = df[['original_text','reference_summary']]\n",
    "df.rename(columns = {'original_text':'source', 'reference_summary':'target'}, inplace = True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:00.447240Z",
     "iopub.status.busy": "2023-10-26T09:49:00.446460Z",
     "iopub.status.idle": "2023-10-26T09:49:00.452326Z",
     "shell.execute_reply": "2023-10-26T09:49:00.451236Z",
     "shell.execute_reply.started": "2023-10-26T09:49:00.447204Z"
    },
    "id": "RnCjv6n7wVrN"
   },
   "outputs": [],
   "source": [
    "X = df['source']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:09.073624Z",
     "iopub.status.busy": "2023-10-26T09:49:09.072672Z",
     "iopub.status.idle": "2023-10-26T09:49:09.089583Z",
     "shell.execute_reply": "2023-10-26T09:49:09.088492Z",
     "shell.execute_reply.started": "2023-10-26T09:49:09.073591Z"
    },
    "id": "K35erKW3cINP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcome to the pok√©mon go video game services ...</td>\n",
       "      <td>hi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>by using our services you are agreeing to thes...</td>\n",
       "      <td>by playing this game you agree to these terms....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if you want to use certain features of the ser...</td>\n",
       "      <td>you have to use google pokemon trainer club or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>during game play please be aware of your surro...</td>\n",
       "      <td>don t die or hurt others and if you do it s no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject to your compliance with these terms ni...</td>\n",
       "      <td>don t copy modify resell distribute or reverse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  welcome to the pok√©mon go video game services ...   \n",
       "1  by using our services you are agreeing to thes...   \n",
       "2  if you want to use certain features of the ser...   \n",
       "3  during game play please be aware of your surro...   \n",
       "4  subject to your compliance with these terms ni...   \n",
       "\n",
       "                                              target  \n",
       "0                                                hi.  \n",
       "1  by playing this game you agree to these terms....  \n",
       "2  you have to use google pokemon trainer club or...  \n",
       "3  don t die or hurt others and if you do it s no...  \n",
       "4  don t copy modify resell distribute or reverse...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:09.092009Z",
     "iopub.status.busy": "2023-10-26T09:49:09.091613Z",
     "iopub.status.idle": "2023-10-26T09:49:09.100324Z",
     "shell.execute_reply": "2023-10-26T09:49:09.099234Z",
     "shell.execute_reply.started": "2023-10-26T09:49:09.091971Z"
    },
    "id": "YuCMAtjGeM86"
   },
   "outputs": [],
   "source": [
    "class LEDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:09.101626Z",
     "iopub.status.busy": "2023-10-26T09:49:09.101352Z",
     "iopub.status.idle": "2023-10-26T09:49:09.112743Z",
     "shell.execute_reply": "2023-10-26T09:49:09.111732Z",
     "shell.execute_reply.started": "2023-10-26T09:49:09.101603Z"
    },
    "id": "NOdzySbseTAg"
   },
   "outputs": [],
   "source": [
    "def prepare_data(model_name,\n",
    "                 train_texts, train_labels,\n",
    "                 test_texts, test_labels):\n",
    "  \"\"\"\n",
    "  Prepare input data for model fine-tuning\n",
    "  \"\"\"\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  prepare_test = False if test_texts is None or test_labels is None else True\n",
    "\n",
    "  def tokenize_data(texts, labels):\n",
    "\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length = 600)\n",
    "    decodings = tokenizer(labels, truncation=True, padding=True, max_length = 256)\n",
    "    dataset_tokenized = LEDDataset(encodings, decodings)\n",
    "    return dataset_tokenized\n",
    "\n",
    "  train_dataset = tokenize_data(train_texts, train_labels)\n",
    "  test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n",
    "\n",
    "  return train_dataset, test_dataset, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:22:53.292405Z",
     "iopub.status.busy": "2023-10-26T10:22:53.291331Z",
     "iopub.status.idle": "2023-10-26T10:22:53.303167Z",
     "shell.execute_reply": "2023-10-26T10:22:53.302176Z",
     "shell.execute_reply.started": "2023-10-26T10:22:53.292367Z"
    },
    "id": "8sFuuoDheVvr"
   },
   "outputs": [],
   "source": [
    "def prepare_fine_tuning(model_name, tokenizer, train_dataset, test_dataset, freeze_encoder=False, output_dir='./results'):\n",
    "  \"\"\"\n",
    "  Prepare configurations and base model for fine-tuning\n",
    "  \"\"\"\n",
    "  torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  model = LEDForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "  if test_dataset is not None:\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=output_dir,           # output directory\n",
    "      num_train_epochs=2,              # total number of training epochs\n",
    "      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
    "      per_device_eval_batch_size=1,    # batch size for evaluation, can increase if memory allows\n",
    "      save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "      evaluation_strategy='steps',     # evaluation strategy to adopt during training\n",
    "      eval_steps=100,                  # number of update steps before evaluation\n",
    "      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "      weight_decay=0.01,               # strength of weight decay\n",
    "      logging_dir='./logs',            # directory for storing logs\n",
    "      logging_steps=100,\n",
    "      report_to=\"wandb\",\n",
    "      run_name = \"longformer\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "      args=training_args,                  # training arguments, defined above\n",
    "      train_dataset=train_dataset,         # training dataset\n",
    "      eval_dataset=test_dataset,           # evaluation dataset\n",
    "      tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "  else:\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=output_dir,           # output directory\n",
    "      num_train_epochs=2,              # total number of training epochs\n",
    "      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
    "      save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "      weight_decay=0.01,               # strength of weight decay\n",
    "      logging_dir='./logs',            # directory for storing logs\n",
    "      logging_steps=100,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "      args=training_args,                  # training arguments, defined above\n",
    "      train_dataset=train_dataset,         # training dataset\n",
    "      tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "  return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:22:56.912114Z",
     "iopub.status.busy": "2023-10-26T10:22:56.911145Z",
     "iopub.status.idle": "2023-10-26T10:22:56.920561Z",
     "shell.execute_reply": "2023-10-26T10:22:56.919409Z",
     "shell.execute_reply.started": "2023-10-26T10:22:56.912077Z"
    },
    "id": "1Qs6bhoOz8uV"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "train_texts, train_labels = list(X_train), list(y_train)\n",
    "test_texts, test_labels = list(X_test), list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:22:58.702992Z",
     "iopub.status.busy": "2023-10-26T10:22:58.701967Z",
     "iopub.status.idle": "2023-10-26T10:28:51.746518Z",
     "shell.execute_reply": "2023-10-26T10:28:51.745649Z",
     "shell.execute_reply.started": "2023-10-26T10:22:58.702953Z"
    },
    "id": "PBpl_Dzoebmd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335ebe8838914e59ae0f5303f81e1db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/648M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a57dd5e7dc64d018f55c6cfe17e64d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)neration_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maarushi-jain211\u001b[0m (\u001b[33mfaltu-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20231026_102309-yab0dfzp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/faltu-team/major-one/runs/yab0dfzp' target=\"_blank\">longformer</a></strong> to <a href='https://wandb.ai/faltu-team/major-one' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/faltu-team/major-one' target=\"_blank\">https://wandb.ai/faltu-team/major-one</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/faltu-team/major-one/runs/yab0dfzp' target=\"_blank\">https://wandb.ai/faltu-team/major-one/runs/yab0dfzp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LEDTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='356' max='356' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [356/356 04:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>9.902600</td>\n",
       "      <td>5.044665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.150700</td>\n",
       "      <td>1.118686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.845200</td>\n",
       "      <td>0.460910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a7ec35e9964831bd4fa5ce2b092434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='620.893 MB of 620.893 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñà‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñà‚ñà‚ñÇ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñÅ‚ñÅ‚ñá</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñÅ‚ñÅ‚ñá</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ‚ñÖ‚ñà</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.43005</td></tr><tr><td>eval/runtime</td><td>7.5266</td></tr><tr><td>eval/samples_per_second</td><td>11.958</td></tr><tr><td>eval/steps_per_second</td><td>5.979</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>356</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.8452</td></tr><tr><td>train/total_flos</td><td>281622926131200.0</td></tr><tr><td>train/train_loss</td><td>4.01028</td></tr><tr><td>train/train_runtime</td><td>267.6063</td></tr><tr><td>train/train_samples_per_second</td><td>2.661</td></tr><tr><td>train/train_steps_per_second</td><td>1.33</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">longformer</strong> at: <a href='https://wandb.ai/faltu-team/major-one/runs/yab0dfzp' target=\"_blank\">https://wandb.ai/faltu-team/major-one/runs/yab0dfzp</a><br/>Synced 6 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231026_102309-yab0dfzp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'allenai/led-base-16384'\n",
    "\n",
    "train_dataset,test_dataset, tokenizer = prepare_data(model_name, train_texts, train_labels,test_texts,test_labels)\n",
    "trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset,test_dataset)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate(test_dataset)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:29:34.189388Z",
     "iopub.status.busy": "2023-10-26T10:29:34.188948Z",
     "iopub.status.idle": "2023-10-26T10:29:35.952550Z",
     "shell.execute_reply": "2023-10-26T10:29:35.951337Z",
     "shell.execute_reply.started": "2023-10-26T10:29:34.189337Z"
    },
    "id": "IlT-HJrKefPH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./ouput_model/'):\n",
    "    os.makedirs('./ouput_model/')\n",
    "trainer.model.save_pretrained(\"./ouput_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtBBBTxTuwmy"
   },
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:29:36.153545Z",
     "iopub.status.busy": "2023-10-26T10:29:36.153184Z",
     "iopub.status.idle": "2023-10-26T10:29:36.158552Z",
     "shell.execute_reply": "2023-10-26T10:29:36.157526Z",
     "shell.execute_reply.started": "2023-10-26T10:29:36.153516Z"
    },
    "id": "S6RupAQGv2G4"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:29:36.589797Z",
     "iopub.status.busy": "2023-10-26T10:29:36.589403Z",
     "iopub.status.idle": "2023-10-26T10:29:36.595138Z",
     "shell.execute_reply": "2023-10-26T10:29:36.593989Z",
     "shell.execute_reply.started": "2023-10-26T10:29:36.589764Z"
    },
    "id": "Vy4oVHjuwA5k"
   },
   "outputs": [],
   "source": [
    "config = PretrainedConfig.from_json_file('./ouput_model/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:30:33.213374Z",
     "iopub.status.busy": "2023-10-26T10:30:33.212596Z",
     "iopub.status.idle": "2023-10-26T10:30:35.756779Z",
     "shell.execute_reply": "2023-10-26T10:30:35.755639Z",
     "shell.execute_reply.started": "2023-10-26T10:30:33.213342Z"
    },
    "id": "wjV9aYqwvsDL"
   },
   "outputs": [],
   "source": [
    "model = LEDForConditionalGeneration.from_pretrained(\"./ouput_model/\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:30:37.026403Z",
     "iopub.status.busy": "2023-10-26T10:30:37.026037Z",
     "iopub.status.idle": "2023-10-26T10:30:37.033713Z",
     "shell.execute_reply": "2023-10-26T10:30:37.032327Z",
     "shell.execute_reply.started": "2023-10-26T10:30:37.026376Z"
    },
    "id": "4eFewXp-vc6F"
   },
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "  input_tokenized = tokenizer.encode(text, return_tensors='pt',max_length=1024,truncation=True).to(device)\n",
    "  summary_ids = model.generate(input_tokenized,\n",
    "                                  num_beams=9,\n",
    "                                  no_repeat_ngram_size=3,\n",
    "                                  length_penalty=2.0,\n",
    "                                  min_length=50,\n",
    "                                  max_length=150,\n",
    "                                  early_stopping=True)\n",
    "  summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n",
    "\n",
    "  return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:30:38.091759Z",
     "iopub.status.busy": "2023-10-26T10:30:38.091355Z",
     "iopub.status.idle": "2023-10-26T10:31:43.563430Z",
     "shell.execute_reply": "2023-10-26T10:31:43.562240Z",
     "shell.execute_reply.started": "2023-10-26T10:30:38.091727Z"
    },
    "id": "-W86Su68vqFv"
   },
   "outputs": [],
   "source": [
    "y_pred = X_test.apply(lambda x: summarize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:31:43.565762Z",
     "iopub.status.busy": "2023-10-26T10:31:43.565462Z",
     "iopub.status.idle": "2023-10-26T10:31:43.571843Z",
     "shell.execute_reply": "2023-10-26T10:31:43.570732Z",
     "shell.execute_reply.started": "2023-10-26T10:31:43.565737Z"
    },
    "id": "Jj6hYeguyHsd"
   },
   "outputs": [],
   "source": [
    "summary = pd.concat([y_test.to_frame(name=\"reference_summary\"), y_pred.to_frame(name=\"generated_summary\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:31:43.573477Z",
     "iopub.status.busy": "2023-10-26T10:31:43.573141Z",
     "iopub.status.idle": "2023-10-26T10:31:43.586449Z",
     "shell.execute_reply": "2023-10-26T10:31:43.585647Z",
     "shell.execute_reply.started": "2023-10-26T10:31:43.573445Z"
    },
    "id": "QbsGPBCqyZoH"
   },
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:31:43.588301Z",
     "iopub.status.busy": "2023-10-26T10:31:43.588027Z",
     "iopub.status.idle": "2023-10-26T10:31:43.720257Z",
     "shell.execute_reply": "2023-10-26T10:31:43.719334Z",
     "shell.execute_reply.started": "2023-10-26T10:31:43.588277Z"
    },
    "id": "zTCns0rhybbx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.5231165604311384,\n",
       "  'p': 0.207027982213309,\n",
       "  'f': 0.28370216792727043},\n",
       " 'rouge-2': {'r': 0.2462429622268355,\n",
       "  'p': 0.07235508415967715,\n",
       "  'f': 0.10572520256578813},\n",
       " 'rouge-l': {'r': 0.46197352354790544,\n",
       "  'p': 0.1807507376035193,\n",
       "  'f': 0.24799084745873354}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores(summary['generated_summary'], summary['reference_summary'],avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
