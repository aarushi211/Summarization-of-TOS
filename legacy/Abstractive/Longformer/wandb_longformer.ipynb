{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T09:46:07.231474Z",
     "iopub.status.busy": "2023-10-26T09:46:07.230673Z",
     "iopub.status.idle": "2023-10-26T09:47:08.838068Z",
     "shell.execute_reply": "2023-10-26T09:47:08.836639Z",
     "shell.execute_reply.started": "2023-10-26T09:46:07.231437Z"
    },
    "id": "C-OBrGewb_Wu",
    "outputId": "3f0a8325-45ac-40e1-eb35-30c681f59eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.38.2 in /usr/local/lib/python3.11/dist-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (2025.7.14)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: rouge in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.38.2\n",
    "!pip install accelerate -U\n",
    "!pip install sentencepiece\n",
    "!pip install rouge\n",
    "!pip install wandb onnx -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "id": "BaJ21_zHmViI",
    "outputId": "bed97506-230a-4de4-ed74-0bcaca8a76df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.38.2\n",
      "Uninstalling transformers-4.38.2:\n",
      "  Successfully uninstalled transformers-4.38.2\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
      "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m174.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m240.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "Successfully installed tokenizers-0.21.2 transformers-4.53.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "a72ee04e7ab848cea60966fe8abb7dcd",
       "pip_warning": {
        "packages": [
         "tokenizers",
         "transformers"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip install transformers --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T09:47:08.840599Z",
     "iopub.status.busy": "2023-10-26T09:47:08.840282Z",
     "iopub.status.idle": "2023-10-26T09:47:09.843462Z",
     "shell.execute_reply": "2023-10-26T09:47:09.842359Z",
     "shell.execute_reply.started": "2023-10-26T09:47:08.840571Z"
    },
    "id": "8-7bYF_qvTDT",
    "outputId": "e56cbbef-ff98-44b9-8821-b5987b4a884d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TOS-Summarization'...\n",
      "remote: Enumerating objects: 291, done.\u001b[K\n",
      "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 291 (delta 38), reused 38 (delta 16), pack-reused 201 (from 1)\u001b[K\n",
      "Receiving objects: 100% (291/291), 845.92 KiB | 2.50 MiB/s, done.\n",
      "Resolving deltas: 100% (138/138), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/aarushi211/TOS-Summarization.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dgx0W_NHmfmb"
   },
   "outputs": [],
   "source": [
    "from transformers import LEDForConditionalGeneration, LEDTokenizer, Trainer, TrainingArguments,pipeline,PretrainedConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:47:09.845275Z",
     "iopub.status.busy": "2023-10-26T09:47:09.844974Z",
     "iopub.status.idle": "2023-10-26T09:47:17.344279Z",
     "shell.execute_reply": "2023-10-26T09:47:17.343270Z",
     "shell.execute_reply.started": "2023-10-26T09:47:09.845246Z"
    },
    "id": "7KBtpTeJbcsA"
   },
   "outputs": [],
   "source": [
    "# from transformers import LEDForConditionalGeneration, LEDTokenizer, Trainer, TrainingArguments,pipeline,PretrainedConfig\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge import Rouge\n",
    "import pandas as pd\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import accelerate\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"]=\"major-one\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"checkpoint\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"all\"\n",
    "\n",
    "\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset location\n",
    "filename = \"./TOS-Summarization/Dataset/all_v1_transpose.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:48:20.112576Z",
     "iopub.status.busy": "2023-10-26T09:48:20.112279Z",
     "iopub.status.idle": "2023-10-26T09:48:32.690811Z",
     "shell.execute_reply": "2023-10-26T09:48:32.689447Z",
     "shell.execute_reply.started": "2023-10-26T09:48:20.112549Z"
    },
    "id": "Y7hFaU9Wkusf",
    "outputId": "a18d0d46-aca4-40b0-8f44-baadb9f84b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.12)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.30.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T09:48:32.692788Z",
     "iopub.status.busy": "2023-10-26T09:48:32.692453Z",
     "iopub.status.idle": "2023-10-26T09:48:33.742706Z",
     "shell.execute_reply": "2023-10-26T09:48:33.741679Z",
     "shell.execute_reply.started": "2023-10-26T09:48:32.692756Z"
    },
    "id": "NquUD6lhfBHO",
    "outputId": "2a0dfbf5-9e01-4820-bd68-14b542a9a57b"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 路路路路路路路路路路\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maarushi-jain211\u001b[0m (\u001b[33mfaltu-team\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:00.417886Z",
     "iopub.status.busy": "2023-10-26T09:49:00.417478Z",
     "iopub.status.idle": "2023-10-26T09:49:00.444373Z",
     "shell.execute_reply": "2023-10-26T09:49:00.443295Z",
     "shell.execute_reply.started": "2023-10-26T09:49:00.417853Z"
    },
    "id": "ERL_fIRDcBOB",
    "outputId": "81afe020-dcd5-45aa-b1b9-8c55e95fcb10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df = df[['original_text','reference_summary']]\n",
    "df.rename(columns = {'original_text':'source', 'reference_summary':'target'}, inplace = True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:00.447240Z",
     "iopub.status.busy": "2023-10-26T09:49:00.446460Z",
     "iopub.status.idle": "2023-10-26T09:49:00.452326Z",
     "shell.execute_reply": "2023-10-26T09:49:00.451236Z",
     "shell.execute_reply.started": "2023-10-26T09:49:00.447204Z"
    },
    "id": "RnCjv6n7wVrN"
   },
   "outputs": [],
   "source": [
    "X = df['source']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:09.073624Z",
     "iopub.status.busy": "2023-10-26T09:49:09.072672Z",
     "iopub.status.idle": "2023-10-26T09:49:09.089583Z",
     "shell.execute_reply": "2023-10-26T09:49:09.088492Z",
     "shell.execute_reply.started": "2023-10-26T09:49:09.073591Z"
    },
    "id": "K35erKW3cINP",
    "outputId": "f21047ef-2cd8-4479-ea0a-f9560239e9c2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 446,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 445,\n        \"samples\": [\n          \"contains any information or content that is illegal.\",\n          \"github uses cookies to make interactions with our service easy and meaningful. we use cookies and similar technologies like html5 localstorage to keep you logged in remember your preferences and provide information for future development of github. we also use cookies to identify a device for security reasons. by using our website you agree that we can place these types of cookies on your computer or device. if you disable your browser or device s ability to accept cookies you will not be able to log in or use github s services. we provide a web page on cookies and tracking that describes the cookies we set the needs we have for those cookies and the types of cookies they are temporary or permanent. it also lists our third party analytics and service providers and details exactly which parts of our website we permit them to track.\",\n          \"we also save searches but again not in a personally identifiable way as we do not store ip addresses or unique user agent strings.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 290,\n        \"samples\": [\n          \"this service does not track you.\",\n          \"user suspension from the service will be fair and proportionate.\",\n          \"the jurisdiction is california.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3035578e-0cb4-4297-9fe5-190155c970b4\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcome to the pok茅mon go video game services ...</td>\n",
       "      <td>hi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>by using our services you are agreeing to thes...</td>\n",
       "      <td>by playing this game you agree to these terms....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if you want to use certain features of the ser...</td>\n",
       "      <td>you have to use google pokemon trainer club or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>during game play please be aware of your surro...</td>\n",
       "      <td>don t die or hurt others and if you do it s no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject to your compliance with these terms ni...</td>\n",
       "      <td>don t copy modify resell distribute or reverse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3035578e-0cb4-4297-9fe5-190155c970b4')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3035578e-0cb4-4297-9fe5-190155c970b4 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3035578e-0cb4-4297-9fe5-190155c970b4');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-e6b5a3fd-ed9c-4b78-9e8d-581609035294\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6b5a3fd-ed9c-4b78-9e8d-581609035294')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-e6b5a3fd-ed9c-4b78-9e8d-581609035294 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  welcome to the pok茅mon go video game services ...   \n",
       "1  by using our services you are agreeing to thes...   \n",
       "2  if you want to use certain features of the ser...   \n",
       "3  during game play please be aware of your surro...   \n",
       "4  subject to your compliance with these terms ni...   \n",
       "\n",
       "                                              target  \n",
       "0                                                hi.  \n",
       "1  by playing this game you agree to these terms....  \n",
       "2  you have to use google pokemon trainer club or...  \n",
       "3  don t die or hurt others and if you do it s no...  \n",
       "4  don t copy modify resell distribute or reverse...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:09.092009Z",
     "iopub.status.busy": "2023-10-26T09:49:09.091613Z",
     "iopub.status.idle": "2023-10-26T09:49:09.100324Z",
     "shell.execute_reply": "2023-10-26T09:49:09.099234Z",
     "shell.execute_reply.started": "2023-10-26T09:49:09.091971Z"
    },
    "id": "YuCMAtjGeM86"
   },
   "outputs": [],
   "source": [
    "class LEDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T09:49:09.101626Z",
     "iopub.status.busy": "2023-10-26T09:49:09.101352Z",
     "iopub.status.idle": "2023-10-26T09:49:09.112743Z",
     "shell.execute_reply": "2023-10-26T09:49:09.111732Z",
     "shell.execute_reply.started": "2023-10-26T09:49:09.101603Z"
    },
    "id": "NOdzySbseTAg"
   },
   "outputs": [],
   "source": [
    "def prepare_data(model_name,\n",
    "                 train_texts, train_labels,\n",
    "                 test_texts, test_labels):\n",
    "  \"\"\"\n",
    "  Prepare input data for model fine-tuning\n",
    "  \"\"\"\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  prepare_test = False if test_texts is None or test_labels is None else True\n",
    "\n",
    "  def tokenize_data(texts, labels):\n",
    "\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length = 600)\n",
    "    decodings = tokenizer(labels, truncation=True, padding=True, max_length = 256)\n",
    "    dataset_tokenized = LEDDataset(encodings, decodings)\n",
    "    return dataset_tokenized\n",
    "\n",
    "  train_dataset = tokenize_data(train_texts, train_labels)\n",
    "  test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n",
    "\n",
    "  return train_dataset, test_dataset, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:22:53.292405Z",
     "iopub.status.busy": "2023-10-26T10:22:53.291331Z",
     "iopub.status.idle": "2023-10-26T10:22:53.303167Z",
     "shell.execute_reply": "2023-10-26T10:22:53.302176Z",
     "shell.execute_reply.started": "2023-10-26T10:22:53.292367Z"
    },
    "id": "8sFuuoDheVvr"
   },
   "outputs": [],
   "source": [
    "def prepare_fine_tuning(model_name, tokenizer, train_dataset, test_dataset, freeze_encoder=False, output_dir='./results'):\n",
    "  \"\"\"\n",
    "  Prepare configurations and base model for fine-tuning\n",
    "  \"\"\"\n",
    "  torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  model = LEDForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "  if test_dataset is not None:\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=output_dir,           # output directory\n",
    "      num_train_epochs=2,              # total number of training epochs\n",
    "      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
    "      per_device_eval_batch_size=1,    # batch size for evaluation, can increase if memory allows\n",
    "      save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "      eval_strategy='steps',     # evaluation strategy to adopt during training\n",
    "      eval_steps=100,                  # number of update steps before evaluation\n",
    "      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "      weight_decay=0.01,               # strength of weight decay\n",
    "      logging_dir='./logs',            # directory for storing logs\n",
    "      logging_steps=100,\n",
    "      report_to=\"wandb\",\n",
    "      run_name = \"longformer\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=model,                         # the instantiated  Transformers model to be trained\n",
    "      args=training_args,                  # training arguments, defined above\n",
    "      train_dataset=train_dataset,         # training dataset\n",
    "      eval_dataset=test_dataset,           # evaluation dataset\n",
    "      tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "  else:\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=output_dir,           # output directory\n",
    "      num_train_epochs=2,              # total number of training epochs\n",
    "      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
    "      save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "      weight_decay=0.01,               # strength of weight decay\n",
    "      logging_dir='./logs',            # directory for storing logs\n",
    "      logging_steps=100,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=model,                         # the instantiated  Transformers model to be trained\n",
    "      args=training_args,                  # training arguments, defined above\n",
    "      train_dataset=train_dataset,         # training dataset\n",
    "      tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "  return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:22:56.912114Z",
     "iopub.status.busy": "2023-10-26T10:22:56.911145Z",
     "iopub.status.idle": "2023-10-26T10:22:56.920561Z",
     "shell.execute_reply": "2023-10-26T10:22:56.919409Z",
     "shell.execute_reply.started": "2023-10-26T10:22:56.912077Z"
    },
    "id": "1Qs6bhoOz8uV"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "train_texts, train_labels = list(X_train), list(y_train)\n",
    "test_texts, test_labels = list(X_test), list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T10:22:58.702992Z",
     "iopub.status.busy": "2023-10-26T10:22:58.701967Z",
     "iopub.status.idle": "2023-10-26T10:28:51.746518Z",
     "shell.execute_reply": "2023-10-26T10:28:51.745649Z",
     "shell.execute_reply.started": "2023-10-26T10:22:58.702953Z"
    },
    "id": "PBpl_Dzoebmd",
    "outputId": "86aa4304-9e6b-4ca0-be19-06f7297bd615"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-12-2676946707.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250721_105119-squngz1s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/faltu-team/major-one/runs/squngz1s' target=\"_blank\">longformer</a></strong> to <a href='https://wandb.ai/faltu-team/major-one' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/faltu-team/major-one' target=\"_blank\">https://wandb.ai/faltu-team/major-one</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/faltu-team/major-one/runs/squngz1s' target=\"_blank\">https://wandb.ai/faltu-team/major-one/runs/squngz1s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 600 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='712' max='712' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [712/712 13:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>10.092100</td>\n",
       "      <td>5.407535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.453200</td>\n",
       "      <td>1.222938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.986700</td>\n",
       "      <td>0.524449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.688500</td>\n",
       "      <td>0.490826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.586600</td>\n",
       "      <td>0.473507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.578300</td>\n",
       "      <td>0.424223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>0.398012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 539 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./results/checkpoint-500)... Done. 76.4s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./results/checkpoint-712)... Done. 22.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.3975</td></tr><tr><td>eval/runtime</td><td>11.3271</td></tr><tr><td>eval/samples_per_second</td><td>7.946</td></tr><tr><td>eval/steps_per_second</td><td>7.946</td></tr><tr><td>total_flos</td><td>281622926131200.0</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>712</td></tr><tr><td>train/grad_norm</td><td>2.35757</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3999</td></tr><tr><td>train_loss</td><td>2.37196</td></tr><tr><td>train_runtime</td><td>677.4342</td></tr><tr><td>train_samples_per_second</td><td>1.051</td></tr><tr><td>train_steps_per_second</td><td>1.051</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">longformer</strong> at: <a href='https://wandb.ai/faltu-team/major-one/runs/squngz1s' target=\"_blank\">https://wandb.ai/faltu-team/major-one/runs/squngz1s</a><br> View project at: <a href='https://wandb.ai/faltu-team/major-one' target=\"_blank\">https://wandb.ai/faltu-team/major-one</a><br>Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250721_105119-squngz1s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'allenai/led-base-16384'\n",
    "\n",
    "train_dataset,test_dataset, tokenizer = prepare_data(model_name, train_texts, train_labels,test_texts,test_labels)\n",
    "trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset,test_dataset)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate(test_dataset)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:29:34.189388Z",
     "iopub.status.busy": "2023-10-26T10:29:34.188948Z",
     "iopub.status.idle": "2023-10-26T10:29:35.952550Z",
     "shell.execute_reply": "2023-10-26T10:29:35.951337Z",
     "shell.execute_reply.started": "2023-10-26T10:29:34.189337Z"
    },
    "id": "IlT-HJrKefPH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./ouput_model/'):\n",
    "    os.makedirs('./ouput_model/')\n",
    "trainer.model.save_pretrained(\"./ouput_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtBBBTxTuwmy"
   },
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:29:36.153545Z",
     "iopub.status.busy": "2023-10-26T10:29:36.153184Z",
     "iopub.status.idle": "2023-10-26T10:29:36.158552Z",
     "shell.execute_reply": "2023-10-26T10:29:36.157526Z",
     "shell.execute_reply.started": "2023-10-26T10:29:36.153516Z"
    },
    "id": "S6RupAQGv2G4"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:29:36.589797Z",
     "iopub.status.busy": "2023-10-26T10:29:36.589403Z",
     "iopub.status.idle": "2023-10-26T10:29:36.595138Z",
     "shell.execute_reply": "2023-10-26T10:29:36.593989Z",
     "shell.execute_reply.started": "2023-10-26T10:29:36.589764Z"
    },
    "id": "Vy4oVHjuwA5k"
   },
   "outputs": [],
   "source": [
    "config = PretrainedConfig.from_json_file('./ouput_model/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:30:33.213374Z",
     "iopub.status.busy": "2023-10-26T10:30:33.212596Z",
     "iopub.status.idle": "2023-10-26T10:30:35.756779Z",
     "shell.execute_reply": "2023-10-26T10:30:35.755639Z",
     "shell.execute_reply.started": "2023-10-26T10:30:33.213342Z"
    },
    "id": "wjV9aYqwvsDL"
   },
   "outputs": [],
   "source": [
    "model = LEDForConditionalGeneration.from_pretrained(\"./ouput_model/\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:30:37.026403Z",
     "iopub.status.busy": "2023-10-26T10:30:37.026037Z",
     "iopub.status.idle": "2023-10-26T10:30:37.033713Z",
     "shell.execute_reply": "2023-10-26T10:30:37.032327Z",
     "shell.execute_reply.started": "2023-10-26T10:30:37.026376Z"
    },
    "id": "4eFewXp-vc6F"
   },
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "  input_tokenized = tokenizer.encode(text, return_tensors='pt',max_length=1024,truncation=True).to(device)\n",
    "  summary_ids = model.generate(input_tokenized,\n",
    "                                  num_beams=9,\n",
    "                                  no_repeat_ngram_size=3,\n",
    "                                  length_penalty=2.0,\n",
    "                                  min_length=50,\n",
    "                                  max_length=150,\n",
    "                                  early_stopping=True)\n",
    "  summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n",
    "\n",
    "  return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T10:30:38.091759Z",
     "iopub.status.busy": "2023-10-26T10:30:38.091355Z",
     "iopub.status.idle": "2023-10-26T10:31:43.563430Z",
     "shell.execute_reply": "2023-10-26T10:31:43.562240Z",
     "shell.execute_reply.started": "2023-10-26T10:30:38.091727Z"
    },
    "id": "-W86Su68vqFv",
    "outputId": "e64a6abe-6dee-45e5-ee1f-128202a846b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 80 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 26 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 133 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 37 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 52 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 41 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 117 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 62 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 199 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 33 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 123 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 56 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 39 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 17 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 149 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 90 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 83 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 43 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 118 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 252 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 61 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 95 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 94 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 119 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 141 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 23 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 55 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 135 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 36 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 57 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 145 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 47 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 24 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 50 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 84 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 60 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 27 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 53 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 40 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 183 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 49 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 35 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 68 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 71 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 458 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 259 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 89 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 99 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 54 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 284 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 72 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 87 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 48 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 51 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 22 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 76 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 111 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 75 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 115 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 77 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 28 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 74 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 42 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 59 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 181 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 13 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 38 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 162 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 427 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 34 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    }
   ],
   "source": [
    "y_pred = X_test.apply(lambda x: summarize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:31:43.565762Z",
     "iopub.status.busy": "2023-10-26T10:31:43.565462Z",
     "iopub.status.idle": "2023-10-26T10:31:43.571843Z",
     "shell.execute_reply": "2023-10-26T10:31:43.570732Z",
     "shell.execute_reply.started": "2023-10-26T10:31:43.565737Z"
    },
    "id": "Jj6hYeguyHsd"
   },
   "outputs": [],
   "source": [
    "summary = pd.concat([y_test.to_frame(name=\"reference_summary\"), y_pred.to_frame(name=\"generated_summary\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T10:31:43.573477Z",
     "iopub.status.busy": "2023-10-26T10:31:43.573141Z",
     "iopub.status.idle": "2023-10-26T10:31:43.586449Z",
     "shell.execute_reply": "2023-10-26T10:31:43.585647Z",
     "shell.execute_reply.started": "2023-10-26T10:31:43.573445Z"
    },
    "id": "QbsGPBCqyZoH"
   },
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-26T10:31:43.588301Z",
     "iopub.status.busy": "2023-10-26T10:31:43.588027Z",
     "iopub.status.idle": "2023-10-26T10:31:43.720257Z",
     "shell.execute_reply": "2023-10-26T10:31:43.719334Z",
     "shell.execute_reply.started": "2023-10-26T10:31:43.588277Z"
    },
    "id": "zTCns0rhybbx",
    "outputId": "5dda2429-ef05-4753-8b95-764246490134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.5334781875713248,\n",
       "  'p': 0.2132543266527927,\n",
       "  'f': 0.2897391765684265},\n",
       " 'rouge-2': {'r': 0.28461445898637894,\n",
       "  'p': 0.09521665734860855,\n",
       "  'f': 0.1349559741024794},\n",
       " 'rouge-l': {'r': 0.49919100906355796,\n",
       "  'p': 0.19860182961287098,\n",
       "  'f': 0.27051192993895784}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores(summary['generated_summary'], summary['reference_summary'],avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dR7_RFNJpfH8"
   },
   "source": [
    "Saving Model to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwFAWALHkush",
    "outputId": "ff67968a-3f24-44f3-e2d8-26fd78f11921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Enter your token (input will not be visible): \n",
      "Add token as git credential? (Y/n) y\n",
      "Token is valid (permission: write).\n",
      "The token `write-token` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `write-token`\n"
     ]
    }
   ],
   "source": [
    "!pip install -q huggingface_hub\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YM3AGQeEpkCu",
    "outputId": "4593e5e1-0348-4c97-de4f-433617139cc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('longformer-TOS/tokenizer_config.json',\n",
       " 'longformer-TOS/special_tokens_map.json',\n",
       " 'longformer-TOS/vocab.json',\n",
       " 'longformer-TOS/merges.txt',\n",
       " 'longformer-TOS/added_tokens.json',\n",
       " 'longformer-TOS/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model.save_pretrained(\"longformer-TOS\")\n",
    "tokenizer.save_pretrained(\"longformer-TOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "efa9208ee6994cb783861ea6a43118dd",
      "1a5b45afd8aa44f1837553ac0edffd6c",
      "fa53dd1f2fd942d499b6a6ccbabfd730",
      "4080553b39784b2daa0bde15d292413a",
      "caa3cbb2a5374f4b82bdeee1848216f3",
      "644ba9d957ea458ab95b2d2ec8be1d13",
      "fca2ae7b4c16465da63410b5cf8514cf",
      "ed6464ef6b1e4d289402333e168a6dc4",
      "1ef7576ae12843f084289533fa1530aa",
      "c425d23aeb48455ab3d2e220a6e5f9d3",
      "f96e41d9a6e04272b9c583c284fb3b18"
     ]
    },
    "id": "fZ60ISZ_pnHW",
    "outputId": "fdc4b312-d9fc-447a-b2d4-f39f84f6bb03"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa9208ee6994cb783861ea6a43118dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/648M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/aarushi-211/TOS-Longformer/commit/366916ee40eac97632ca17b3942e00ae6f37c5c3', commit_message='Upload folder using huggingface_hub', commit_description='', oid='366916ee40eac97632ca17b3942e00ae6f37c5c3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/aarushi-211/TOS-Longformer', endpoint='https://huggingface.co', repo_type='model', repo_id='aarushi-211/TOS-Longformer'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo, upload_folder\n",
    "\n",
    "hf_username = \"aarushi-211\"\n",
    "model_name = \"TOS-Longformer\"\n",
    "repo_id = f\"{hf_username}/{model_name}\"\n",
    "\n",
    "create_repo(repo_id=repo_id, exist_ok=True)\n",
    "\n",
    "upload_folder(\n",
    "    folder_path=\"longformer-TOS\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBRPWlBZqDSZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1a5b45afd8aa44f1837553ac0edffd6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_644ba9d957ea458ab95b2d2ec8be1d13",
      "placeholder": "",
      "style": "IPY_MODEL_fca2ae7b4c16465da63410b5cf8514cf",
      "value": "Uploading...:93%"
     }
    },
    "1ef7576ae12843f084289533fa1530aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4080553b39784b2daa0bde15d292413a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c425d23aeb48455ab3d2e220a6e5f9d3",
      "placeholder": "",
      "style": "IPY_MODEL_f96e41d9a6e04272b9c583c284fb3b18",
      "value": "602M/648M[00:22&lt;00:01,30.2MB/s]"
     }
    },
    "644ba9d957ea458ab95b2d2ec8be1d13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c425d23aeb48455ab3d2e220a6e5f9d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caa3cbb2a5374f4b82bdeee1848216f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed6464ef6b1e4d289402333e168a6dc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efa9208ee6994cb783861ea6a43118dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a5b45afd8aa44f1837553ac0edffd6c",
       "IPY_MODEL_fa53dd1f2fd942d499b6a6ccbabfd730",
       "IPY_MODEL_4080553b39784b2daa0bde15d292413a"
      ],
      "layout": "IPY_MODEL_caa3cbb2a5374f4b82bdeee1848216f3"
     }
    },
    "f96e41d9a6e04272b9c583c284fb3b18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa53dd1f2fd942d499b6a6ccbabfd730": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed6464ef6b1e4d289402333e168a6dc4",
      "max": 647614116,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ef7576ae12843f084289533fa1530aa",
      "value": 602369341
     }
    },
    "fca2ae7b4c16465da63410b5cf8514cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
